{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-12. 프로젝트 (2) load_wine : 와인을 분류해 봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와인을 분류하는 문제다. class 0부터 2까지 3개의 클래스로 분류할 것이다. 사이킷런 데이터셋에 내장된 이미지를 불러오고 sklearn.model_selection으로 데이터를 분류한다. 마지막으로 다양한 모델을 만들어 성능을 비교한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "wine.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits이라는 변수에 손글씨 데이터를 저장하고 몇 가지 정보가 있음을 확인하였다. 'data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR' 총 7개의 정보가 담겨있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = wine.data\n",
    "wine_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 크기를 확인해보니 총 178개의 데이터와 13개의 특성값을 갖고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "wine_label = wine.target\n",
    "print(wine_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits 데이터의 target을 digits_label의 변수에 저장하였다. 형태를 확인하니 총 178의 데이터가 들어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라벨의 이름을 확인해보니 class 0 부터 2까지로 이루어졌음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와인 문제는 1988년에 R.A. Fisher으로부터 시작되었다. 특성의 수가 13개인데 Alcohol, Malic acid, Ash 등으로 이루어졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  142 , X_test 개수:  36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.model_selection에 내장된 train_test_split을 이용하여 train, test 데이터를 분리하였다. test_size를 0.2로 두어 전체 데이터셋의 20%를 시험용 데이터, 나머지는 훈련 데이터로 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와인 문제 또한 손글씨 문제와 마찬가지로 해당 클래스를 빠뜨리지 않는 것이 중요하다. 분류 문제에서 검출율을 말하는 recall과 정확도를 말하는 precision으로 나뉠 수 있다. recall은 물1체들을 빠뜨리지 않고 얼마나 잘 잡아내는지를 나타내고, precision은 검출된 결과가 얼마나 정확한지 즉 검출된 결과 중 실제 물체가 얼마나 포함되어 있는지를 나타낸다. 이 문제에서는 Recall 값을 확인하여 성능을 비교할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "decision_tree_y_pred = decision_tree.predict(X_test)\n",
    "print(classification_report(y_test, decision_tree_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree model의 정확도는 0.95이다. Decision Tree는 결정경계가 데이터 축에 수직이어서 특정 데이터에만 작동하는 문제가 있다. 이를 극복하기 위해 제안된 모델이 Random Forest이므로 다음과 같이 학습하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest_y_pred = random_forest.predict(X_test)\n",
    "print(classification_report(y_test, random_forest_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 말한 Decision Tree의 단점을 극복한 모델인 Random forest model의 정확도는 1.00이다. Random Forest는 여러 개의 Decision Tree를 모아 놓아 예측 성능을 높일 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, svm_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model의 정확도는 0.55이다. 손글씨 문제와 비교하여 낮은 정확도를 보였는데 이는 전처리 과정을 겪지 않아 이 같은 결과를 보였을 것으로 추정된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.71      0.77        17\n",
      "           2       0.71      0.83      0.77        12\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.82      0.85      0.83        36\n",
      "weighted avg       0.81      0.81      0.80        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "sgd_y_pred = sgd_model.predict(X_test)\n",
    "print(classification_report(y_test, sgd_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD model의 정확도는 0.81이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter = 4000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "logistic_y_pred = logistic_model.predict(X_test)\n",
    "print(classification_report(y_test, logistic_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic model의 정확도는 0.97이다. 다섯 개의 모델 중 두 번째로 높은 정확도를 보인다. 로지스틱 회귀는 회귀를 사용하여 데이터가 어떤 클래스에 속할 것인지 확률을 예측하여 그 확률에 따라 데이터를 분류한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.9502923976608186\n",
      "Random Forest: 1.0\n",
      "SVM: 0.5502136752136751\n",
      "SGD: 0.8129960317460316\n",
      "Logistic Regression: 0.9737654320987654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print('Decision Tree: {}'.format(precision_score(y_test, decision_tree_y_pred, average='weighted')))\n",
    "print('Random Forest: {}'.format(precision_score(y_test, random_forest_y_pred, average='weighted')))\n",
    "print('SVM: {}'.format(precision_score(y_test, svm_y_pred, average='weighted')))\n",
    "print('SGD: {}'.format(precision_score(y_test, sgd_y_pred, average='weighted')))\n",
    "print('Logistic Regression: {}'.format(precision_score(y_test, logistic_y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와인 분류하는 작업을 하였다. 이 문제는 와인을 정확하게 분류하였는지가 중요하기 때문에 Precision 값을 확인하였는데 Random Forest가 1.00라는 가장 높은 값을 나타냈다. 이유는 Random Forest가 와인 데이터 중 특정한 데이터를 분류하기에 우수하기 때문이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 총평"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn을 통하여 내장된 다양한 분류 모델을 사용하여 데이터를 분류하였다. 손글씨 분류와 와인 분류 문제를 진행하며 데이터 특성에 따라 모델의 성능이 달라짐을 알 수 있다. 손글씨 문제에서는 SVM model이, 와인 문제에서는 Random Forest가 예측 성능이 높은 것을 배웠으므로 앞으로 분류를 진행할 때 다양한 분류 모델을 적용하여 성능을 확인할 것이다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
