{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amended-ordinance",
   "metadata": {},
   "source": [
    "# (E6) 프로젝트: 멋진 작사가 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-frontier",
   "metadata": {},
   "source": [
    "## 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "monthly-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget https://aiffelstaticprd.blob.core.windows.net/media/documents/song_lyrics.zip\n",
    "# ! unzip song_lyrics.zip -d ~/aiffel/lyricist/data/lyrics  #lyrics 폴더에 압축풀기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-portugal",
   "metadata": {},
   "source": [
    "## 2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-richmond",
   "metadata": {},
   "source": [
    "glob 모듈을 사용하면 파일을 읽어오는 작업을 하기가 아주 용이해요. glob 를 활용하여 모든 txt 파일을 읽어온 후, raw_corpus 리스트에 문장 단위로 저장하도록 할게요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floppy-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['The first words that come out', 'And I can see this song will be about you', \"I can't believe that I can breathe without you\", 'But all I need to do is carry on', 'The next line I write down', \"And there's a tear that falls between the pages\", \"I know that pain's supposed to heal in stages\", \"But it depends which one I'm standing on I write lines down, then rip them up\", \"Describing love can't be this tough I could set this song on fire, send it up in smoke\", 'I could throw it in the river and watch it sink in slowly']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-repeat",
   "metadata": {},
   "source": [
    "## 3. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-associate",
   "metadata": {},
   "source": [
    "- preprocess_sentence() 함수를 이용해 데이터를 정제하겠습니다. \n",
    "- 지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거하겠습니다.\n",
    "- 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습데이터에서 제외합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tender-lecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "import re                  # 정규표현식을 위한 Regex 지원 모듈 (문장 데이터를 정돈하기 위해) \n",
    "import numpy as np         # 변환된 문장 데이터(행렬)을 편하게 처리하기 위해\n",
    "import tensorflow as tf    # 대망의 텐서플로우!\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()       # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "  \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>'      # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))   # 이 문장이 어떻게 필터링되는지 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "major-madagascar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> the first words that come out <end>',\n",
       " '<start> and i can see this song will be about you <end>',\n",
       " '<start> i can t believe that i can breathe without you <end>',\n",
       " '<start> but all i need to do is carry on <end>',\n",
       " '<start> the next line i write down <end>',\n",
       " '<start> and there s a tear that falls between the pages <end>',\n",
       " '<start> i know that pain s supposed to heal in stages <end>',\n",
       " '<start> but it depends which one i m standing on i write lines down , then rip them up <end>',\n",
       " '<start> describing love can t be this tough i could set this song on fire , send it up in smoke <end>',\n",
       " '<start> i could throw it in the river and watch it sink in slowly <end>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in :\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "        \n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "        \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "israeli-venice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   6 241 ...   0   0   0]\n",
      " [  2   8   5 ...   0   0   0]\n",
      " [  2   5  32 ...   0   0   0]\n",
      " ...\n",
      " [  2 133 117 ...   0   0   0]\n",
      " [  2 133 117 ...   0   0   0]\n",
      " [  2 133 117 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f4a54ca5e10>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "improving-sound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   6 241 426  17  66  56   3   0   0   0   0   0   0   0]\n",
      " [  2   8   5  32  64  42 334  88  27 113   7   3   0   0   0]\n",
      " [  2   5  32  15 217  17   5  32 795 258   7   3   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appreciated-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sensitive-killing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   6 241 426  17  66  56   3   0   0   0   0   0   0]\n",
      "[  6 241 426  17  66  56   3   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  # tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다. 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "tgt_input = tensor[:, 1:]    # tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-jumping",
   "metadata": {},
   "source": [
    "## 4. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-repair",
   "metadata": {},
   "source": [
    "- 훈련 데이터와 평가 데이터를 분리합니다.\n",
    "- 총 데이터의 20%를 평가 데이터셋으로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "toxic-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nominated-modeling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "welcome-lincoln",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 256, 14), (256, 256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
    "dataset_val = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "amino-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (140599, 14)\n",
      "Target Train: (140599, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-driving",
   "metadata": {},
   "source": [
    "만약 결과가 다르다면 천천히 과정을 다시 살펴 동일한 결과를 얻도록 하세요! 만약 학습데이터 갯수가 124960보다 크다면 위 Step 3.의 데이터 정제 과정을 다시한번 검토해 보시기를 권합니다.\n",
    "\n",
    "$- >$ 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습데이터에서 제외하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-ballet",
   "metadata": {},
   "source": [
    "## 5. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "occasional-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abroad-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-8.93310789e-05,  1.78819944e-04,  1.74000510e-04, ...,\n",
       "         -1.99288726e-04,  9.79945544e-05, -1.56782320e-04],\n",
       "        [-3.13257711e-04,  1.73907727e-04,  4.54257999e-04, ...,\n",
       "          1.47738774e-05,  1.62724740e-04, -3.78803205e-04],\n",
       "        [-3.23566812e-04,  1.24466489e-04,  4.83063282e-04, ...,\n",
       "          3.00054147e-04,  3.03616671e-05, -4.53804940e-04],\n",
       "        ...,\n",
       "        [ 1.21042109e-03,  1.62642729e-03, -1.17626099e-03, ...,\n",
       "          1.84738229e-03,  1.13646861e-03, -1.62270817e-03],\n",
       "        [ 1.52494886e-03,  1.60777429e-03, -1.63346110e-03, ...,\n",
       "          1.96431088e-03,  1.21626898e-03, -1.92542805e-03],\n",
       "        [ 1.82063552e-03,  1.52868393e-03, -2.07377481e-03, ...,\n",
       "          2.06462410e-03,  1.24735176e-03, -2.17479514e-03]],\n",
       "\n",
       "       [[-8.93310789e-05,  1.78819944e-04,  1.74000510e-04, ...,\n",
       "         -1.99288726e-04,  9.79945544e-05, -1.56782320e-04],\n",
       "        [-2.03646603e-04,  4.19981778e-04,  4.70208761e-04, ...,\n",
       "         -4.90181556e-04,  2.52901867e-04, -3.72892740e-04],\n",
       "        [-3.11631797e-04,  4.59319650e-04,  6.76137453e-04, ...,\n",
       "         -5.96587197e-04,  5.34833642e-04, -2.89667456e-04],\n",
       "        ...,\n",
       "        [ 2.11643404e-03,  8.57759733e-04, -2.71420763e-03, ...,\n",
       "          1.91265461e-03,  1.51500048e-03, -2.62225047e-03],\n",
       "        [ 2.34526326e-03,  7.37636816e-04, -3.06313625e-03, ...,\n",
       "          2.05547479e-03,  1.41895539e-03, -2.72677676e-03],\n",
       "        [ 2.54657306e-03,  6.15204044e-04, -3.36357648e-03, ...,\n",
       "          2.17375858e-03,  1.31912273e-03, -2.79851793e-03]],\n",
       "\n",
       "       [[-8.93310789e-05,  1.78819944e-04,  1.74000510e-04, ...,\n",
       "         -1.99288726e-04,  9.79945544e-05, -1.56782320e-04],\n",
       "        [-8.07677498e-05,  2.51712307e-04,  2.76061706e-04, ...,\n",
       "         -2.02639509e-04,  4.13059344e-04, -5.23392169e-04],\n",
       "        [ 1.78156206e-05,  3.28050985e-04,  3.67869827e-04, ...,\n",
       "         -4.29953834e-05,  6.85754174e-04, -8.31985672e-04],\n",
       "        ...,\n",
       "        [ 1.00367039e-03,  1.07127090e-03, -1.40567683e-03, ...,\n",
       "          4.63930046e-04,  1.39682658e-03, -1.99920149e-03],\n",
       "        [ 1.28823868e-03,  1.14294980e-03, -1.81856914e-03, ...,\n",
       "          8.33327358e-04,  1.44472963e-03, -2.18455493e-03],\n",
       "        [ 1.57414353e-03,  1.15822232e-03, -2.22024764e-03, ...,\n",
       "          1.15791522e-03,  1.44913339e-03, -2.34893779e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-8.93310789e-05,  1.78819944e-04,  1.74000510e-04, ...,\n",
       "         -1.99288726e-04,  9.79945544e-05, -1.56782320e-04],\n",
       "        [-1.79916446e-04,  3.50210059e-04, -2.73689104e-04, ...,\n",
       "         -2.52803846e-04, -4.44784109e-06, -2.41615227e-04],\n",
       "        [-2.94364261e-04,  2.93838704e-04, -5.02829731e-04, ...,\n",
       "         -1.98778958e-04, -1.70421758e-04,  1.01894475e-04],\n",
       "        ...,\n",
       "        [ 8.80245469e-04,  2.76355771e-04, -7.51563581e-04, ...,\n",
       "          1.03749754e-03,  1.75871456e-03, -9.58095770e-04],\n",
       "        [ 1.18167803e-03,  3.26037087e-04, -1.17975275e-03, ...,\n",
       "          1.31214666e-03,  1.80640700e-03, -1.32596889e-03],\n",
       "        [ 1.47871557e-03,  3.36231402e-04, -1.60944578e-03, ...,\n",
       "          1.54440606e-03,  1.79511751e-03, -1.64257630e-03]],\n",
       "\n",
       "       [[-8.93310789e-05,  1.78819944e-04,  1.74000510e-04, ...,\n",
       "         -1.99288726e-04,  9.79945544e-05, -1.56782320e-04],\n",
       "        [-5.56604427e-05,  1.94293185e-04,  1.03630817e-04, ...,\n",
       "         -3.42483487e-04,  2.00977840e-04, -3.17235274e-04],\n",
       "        [-5.71444434e-05,  3.57642894e-05,  5.81209242e-05, ...,\n",
       "         -3.82616097e-04,  2.20364207e-04, -6.95580675e-04],\n",
       "        ...,\n",
       "        [-2.78131076e-04, -3.37373931e-05, -7.88719859e-04, ...,\n",
       "          3.57407553e-04,  6.03666238e-04, -1.10519794e-03],\n",
       "        [-5.64279253e-05,  1.06491614e-04, -1.05435483e-03, ...,\n",
       "          6.61811559e-04,  8.94547440e-04, -1.35328062e-03],\n",
       "        [ 2.04100084e-04,  2.21021866e-04, -1.37928058e-03, ...,\n",
       "          9.49003908e-04,  1.12184312e-03, -1.63793727e-03]],\n",
       "\n",
       "       [[-8.93310789e-05,  1.78819944e-04,  1.74000510e-04, ...,\n",
       "         -1.99288726e-04,  9.79945544e-05, -1.56782320e-04],\n",
       "        [-1.84374643e-04,  4.65816935e-04,  4.94794804e-04, ...,\n",
       "         -4.82476753e-04,  3.00531508e-04, -1.47917686e-04],\n",
       "        [-3.27350979e-04,  6.47898880e-04,  6.07060269e-04, ...,\n",
       "         -5.12294180e-04,  2.45385978e-04, -3.46377870e-04],\n",
       "        ...,\n",
       "        [ 1.43498939e-03,  9.87845007e-04, -1.74186297e-03, ...,\n",
       "          1.58841384e-03,  1.70594594e-03, -2.17613066e-03],\n",
       "        [ 1.73651113e-03,  8.89923424e-04, -2.20583985e-03, ...,\n",
       "          1.79053762e-03,  1.65411120e-03, -2.38615810e-03],\n",
       "        [ 2.00958876e-03,  7.76595029e-04, -2.62239273e-03, ...,\n",
       "          1.95791735e-03,  1.57776463e-03, -2.55119405e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "occasional-router",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-stereo",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "blessed-criterion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "549/549 [==============================] - 77s 140ms/step - loss: 2.7997 - val_loss: 2.8368\n",
      "Epoch 2/10\n",
      "549/549 [==============================] - 79s 144ms/step - loss: 2.6013 - val_loss: 2.7593\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 81s 147ms/step - loss: 2.4360 - val_loss: 2.7042\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 77s 139ms/step - loss: 2.2899 - val_loss: 2.6613\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 77s 139ms/step - loss: 2.1588 - val_loss: 2.6237\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 77s 139ms/step - loss: 2.0388 - val_loss: 2.5984\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 77s 140ms/step - loss: 1.9283 - val_loss: 2.5814\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 76s 138ms/step - loss: 1.8248 - val_loss: 2.5633\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 76s 139ms/step - loss: 1.7274 - val_loss: 2.5610\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 76s 139ms/step - loss: 1.6355 - val_loss: 2.5487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f49e8145290>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset, epochs=10, validation_data=(enc_val, dec_val), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-england",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "technical-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=15):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "                                                                 tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "realistic-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> i love you , i m not gonna crack <end> \n",
      "<start> i can t help it if i wanted to <end> \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=15))\n",
    "print(generate_text(model, tokenizer, init_sentence=\"<start> i can\", max_len=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-minute",
   "metadata": {},
   "source": [
    "## validation loss 줄이기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-gospel",
   "metadata": {},
   "source": [
    "validation loss를 줄이기 위해 hidden_size를 1024에서 2048로 증가시켰습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "complicated-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 2048\n",
    "model_2 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "former-lender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[ 7.04482372e-05, -1.16639003e-05,  1.19799050e-04, ...,\n",
       "         -5.14395797e-05, -1.00212543e-04,  2.33797095e-04],\n",
       "        [ 5.09734891e-05,  7.97531175e-05, -4.19307726e-05, ...,\n",
       "         -2.28043893e-04, -1.16066258e-04,  1.38302537e-04],\n",
       "        [ 1.13307600e-04,  2.97581311e-04, -5.71191020e-04, ...,\n",
       "         -3.43477092e-04, -3.10152740e-04,  1.06233128e-04],\n",
       "        ...,\n",
       "        [ 1.29651889e-05, -3.85121733e-04,  5.74893875e-07, ...,\n",
       "          1.97815709e-04,  2.58338900e-04, -7.11387565e-06],\n",
       "        [ 6.05874287e-04, -4.81581112e-04, -3.45603212e-06, ...,\n",
       "          4.28660598e-04,  3.25734611e-04, -1.65696110e-04],\n",
       "        [ 1.27169525e-03, -5.74430334e-04, -2.81298326e-05, ...,\n",
       "          6.97627664e-04,  3.30417795e-04, -3.87523411e-04]],\n",
       "\n",
       "       [[ 7.04482372e-05, -1.16639003e-05,  1.19799050e-04, ...,\n",
       "         -5.14395797e-05, -1.00212543e-04,  2.33797095e-04],\n",
       "        [-2.45659205e-04, -1.13071073e-05,  2.99447594e-04, ...,\n",
       "         -1.94787644e-04, -1.40766075e-04,  2.57765409e-04],\n",
       "        [-2.98039115e-04,  5.87482245e-05,  3.66219814e-04, ...,\n",
       "         -1.02607453e-04, -1.78766932e-04,  4.17439762e-04],\n",
       "        ...,\n",
       "        [ 1.77067681e-03,  9.86900530e-04,  9.72002686e-04, ...,\n",
       "          2.17528563e-04, -2.50472804e-04,  6.15678728e-04],\n",
       "        [ 2.35658069e-03,  8.49227363e-04,  9.24221822e-04, ...,\n",
       "          3.43004736e-04, -1.50767053e-04,  3.31743417e-04],\n",
       "        [ 2.98391213e-03,  6.71503542e-04,  8.39757733e-04, ...,\n",
       "          5.16597356e-04, -9.48201705e-05, -1.20725199e-05]],\n",
       "\n",
       "       [[ 7.04482372e-05, -1.16639003e-05,  1.19799050e-04, ...,\n",
       "         -5.14395797e-05, -1.00212543e-04,  2.33797095e-04],\n",
       "        [ 4.18703741e-04,  1.23517675e-04,  9.97470706e-05, ...,\n",
       "         -1.35950744e-04, -4.19265707e-04,  3.92587302e-04],\n",
       "        [ 8.19920213e-04, -7.79508046e-05, -1.55037356e-04, ...,\n",
       "         -4.11328801e-04, -6.90002576e-04,  5.00232331e-04],\n",
       "        ...,\n",
       "        [ 2.06456520e-03, -1.09793257e-03, -1.72033499e-04, ...,\n",
       "         -1.77613541e-03,  4.33319714e-04,  7.02008372e-04],\n",
       "        [ 2.44594249e-03, -1.14658335e-03, -9.82056299e-05, ...,\n",
       "         -1.51704147e-03,  5.09319711e-04,  3.65844637e-04],\n",
       "        [ 2.89464230e-03, -1.17554283e-03, -5.06968463e-05, ...,\n",
       "         -1.17974041e-03,  5.13356295e-04, -8.41084238e-06]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 7.04482372e-05, -1.16639003e-05,  1.19799050e-04, ...,\n",
       "         -5.14395797e-05, -1.00212543e-04,  2.33797095e-04],\n",
       "        [ 1.60515803e-04, -1.09478307e-04,  7.72199128e-05, ...,\n",
       "         -3.88793378e-05, -6.00299209e-05,  4.71765612e-04],\n",
       "        [ 2.76298641e-04, -9.19680679e-05,  1.31606983e-04, ...,\n",
       "         -8.91655363e-05,  2.13753974e-05,  5.62840491e-04],\n",
       "        ...,\n",
       "        [ 4.28222062e-04,  3.62554827e-04, -2.77002371e-04, ...,\n",
       "         -6.89353154e-04,  1.00606808e-03,  5.70156553e-04],\n",
       "        [ 2.79987406e-04,  6.50347734e-04, -1.11563946e-04, ...,\n",
       "         -7.78404356e-04,  1.31446449e-03,  6.31723320e-04],\n",
       "        [-3.12148441e-05,  7.88529578e-04,  1.43506113e-04, ...,\n",
       "         -9.11319396e-04,  1.43053615e-03,  4.39398194e-04]],\n",
       "\n",
       "       [[-6.32093506e-05, -1.85333338e-05,  9.38004450e-05, ...,\n",
       "         -8.06036041e-05,  2.13147781e-04,  7.87722383e-05],\n",
       "        [-4.41473792e-04, -7.78100875e-05,  1.52385241e-04, ...,\n",
       "         -8.08299137e-06,  3.41787818e-04,  2.70030869e-04],\n",
       "        [-9.38227051e-04, -1.43777681e-04,  1.83378448e-04, ...,\n",
       "          1.23862745e-04,  3.88076733e-04,  5.26239804e-04],\n",
       "        ...,\n",
       "        [-1.14872644e-03,  5.83367830e-04,  1.34765694e-03, ...,\n",
       "          2.12741463e-04, -1.12121715e-03,  8.86168797e-04],\n",
       "        [-9.36547294e-04,  5.93256380e-04,  1.41942862e-03, ...,\n",
       "         -7.54474459e-05, -1.30407454e-03,  1.20856694e-03],\n",
       "        [-6.68113469e-04,  5.70497185e-04,  1.13379722e-03, ...,\n",
       "         -4.13860107e-04, -1.35414989e-03,  1.28895335e-03]],\n",
       "\n",
       "       [[ 7.04482372e-05, -1.16639003e-05,  1.19799050e-04, ...,\n",
       "         -5.14395797e-05, -1.00212543e-04,  2.33797095e-04],\n",
       "        [ 8.64349786e-05, -1.95186381e-04,  3.78524157e-04, ...,\n",
       "         -1.72582440e-04, -2.06306780e-04,  9.12628821e-05],\n",
       "        [ 1.38718184e-04, -5.50977129e-04,  3.56277247e-04, ...,\n",
       "         -2.04246477e-04, -3.36257333e-04, -7.88546531e-05],\n",
       "        ...,\n",
       "        [ 3.32750170e-03, -9.31326649e-04, -1.76954636e-04, ...,\n",
       "          1.20096433e-03, -3.23429500e-04, -1.34107878e-03],\n",
       "        [ 3.76417325e-03, -9.06500616e-04, -2.12230560e-04, ...,\n",
       "          1.34290115e-03, -3.67198518e-04, -1.53195171e-03],\n",
       "        [ 4.14210092e-03, -8.64968868e-04, -2.35942483e-04, ...,\n",
       "          1.45920843e-03, -3.99775221e-04, -1.67493930e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model_2(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "sophisticated-consultation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               multiple                  18882560  \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 80,107,489\n",
      "Trainable params: 80,107,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "alternate-dream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "549/549 [==============================] - 214s 390ms/step - loss: 3.5673 - val_loss: 3.1577\n",
      "Epoch 2/10\n",
      "549/549 [==============================] - 214s 390ms/step - loss: 2.9818 - val_loss: 2.8786\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 222s 405ms/step - loss: 2.6664 - val_loss: 2.6867\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 225s 410ms/step - loss: 2.3634 - val_loss: 2.5471\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 224s 408ms/step - loss: 2.0743 - val_loss: 2.4473\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 229s 418ms/step - loss: 1.8067 - val_loss: 2.3753\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 225s 410ms/step - loss: 1.5713 - val_loss: 2.3364\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 223s 405ms/step - loss: 1.3721 - val_loss: 2.3166\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 225s 411ms/step - loss: 1.2132 - val_loss: 2.3189\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 218s 397ms/step - loss: 1.0956 - val_loss: 2.3349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f49484fc450>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model_2.compile(loss=loss, optimizer=optimizer)\n",
    "model_2.fit(dataset, epochs=10, validation_data=(enc_val, dec_val), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-viking",
   "metadata": {},
   "source": [
    "val_loss: 2.5487 -> 2.3349로 감소하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "spectacular-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model_2, tokenizer, init_sentence=\"<start>\", max_len=15):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "                                                                 tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efficient-bubble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> i love forgiveness forgiveness forgiveness iv iv iv moves yin suicide suicide suicide babys \n",
      "<start> i can explicit tea street lamb prick acting caps caps cot cot quick cursive \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_2, tokenizer, init_sentence=\"<start> i love\", max_len=15))\n",
    "print(generate_text(model_2, tokenizer, init_sentence=\"<start> i can\", max_len=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-rover",
   "metadata": {},
   "source": [
    "## 6. 루브릭"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-prescription",
   "metadata": {},
   "source": [
    "1. 가사 텍스트 생성 모델이 정상적으로 동작하는가?\n",
    "\n",
    "hidden_size가 1024일 때 가사 텍스트 생성 모델이 정상적으로 작동했습니다.\n",
    "hidden_size가 2048일 때는 가사 텍스트 생성 모델에서 단어가 비정상적으로 반복되는 모습을 보입니다.\n",
    "\n",
    "2. 데이터의 전처리와 데이터셋 구성 과정이 체계적으로 진행되었는가?\n",
    "\n",
    "특수문자 제거, 토크나이저 생성, 패딩처리 등의 과정이 빠짐없이 진행되었습니다.\n",
    "토큰화 과정에서 토큰의 개수를 15개로 제한하였습니다.(maxlen = 15)\n",
    "\n",
    "3. 텍스트 생성모델이 안정적으로 학습되었는가?\n",
    "\n",
    "텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?\n",
    "\n",
    "hidden_size를 1024에서 2048로 증가시켜서 validation loss를 줄이는데 성공하였지만 여전히 2.3349의 값으로 2.2 이하로 낮추는 데는 실패하였다. epoch 8회 이상부터 validation loss가 증가한 것을 보니 모델이 overfitting 되었음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-liquid",
   "metadata": {},
   "source": [
    "이 프로젝트에서는 validation loss를 줄이기 위해서 hidden_size만 2배 증가시켰는데 hyperparameter인 embedding_size 또한 증가시키면 validation loss가 감소될 것이라고 추측됩니다. 데이터가 크기 때문에 모델의 학습 시간이 오래걸렸는데 모델의 학습 시간을 줄이기 위한 공부가 필요할 것 같습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
