{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-11. 프로젝트 (1) load_digits : 손글씨를 분류해 봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손글씨 이미지를 분류하는 문제다. 숫자 0-9까지의 10개의 클래스로 분류할 것이다. 사이킷런 데이터셋에 내장된 이미지를 불러오고 sklearn.model_selection으로 데이터를 분류하여 다양한 모델을 만들어 성능을 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits이라는 변수에 손글씨 데이터를 저장하고 몇 가지 정보가 있음을 확인하였다. 'data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR' 총 7개의 정보가 담겨있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data = digits.data\n",
    "digits_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 크기를 확인해보니 총 1797개의 데이터와 64개의 특성값을 갖고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "digits_label = digits.target\n",
    "print(digits_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits 데이터의 target을 digits_label의 변수에 저장하였다. 형태를 확인하니 총 1797의 데이터가 들어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라벨의 이름을 확인해보니 0-9의 숫자로 이루어졌음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손글씨 문제는 1988년에 E. Alpaydin으로부터 시작되었다. 특성의 수가 64개인데 (8x8) 크기의 이미지를 일렬로 펼쳐 놓은 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  1437 , X_test 개수:  360\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.model_selection에 내장된 train_test_split을 이용하여 train, test 데이터를 분리하였다. test_size를 0.2로 두어 전체 데이터셋의 20%를 시험용 데이터, 나머지는 훈련 데이터로 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손글씨 문제는 해당 숫자를 빠뜨리지 않는 것이 중요하다. 이미지 인식을 다루는 문제에서 검출율을 말하는 Recall과 정확도를 말하는 Precision으로 나뉠 수 있다. Recall은 물체들을 빠뜨리지 않고 얼마나 잘 잡아내는지를 나타내고, Precision은 검출된 결과가 얼마나 정확한지 즉 검출된 결과 중 실제 물체가 얼마나 포함되어 있는지를 나타낸다. 이 문제에서는 Precision 값을 확인하여 성능을 비교할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "decision_tree_y_pred = decision_tree.predict(X_test)\n",
    "print(classification_report(y_test, decision_tree_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree model의 정확도는 0.86이다. Decision Tree는 결정경계가 데이터 축에 수직이어서 특정 데이터에만 작동하는 문제가 있다. 이를 극복하기 위해 제안된 모델이 Random Forest이므로 다음과 같이 학습하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest_y_pred = random_forest.predict(X_test)\n",
    "print(classification_report(y_test, random_forest_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 말한 Decision Tree의 단점을 극복한 모델인 Random forest model의 정확도는 0.97이다. Random Forest는 여러 개의 Decision Tree를 모아 놓아 예측 성능을 높일 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, svm_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model의 정확도는 0.99이다. SVM은 클래스를 분류할 때 데이터를 높은 차원 공간으로 변환하는 커널함수를 이용하여서 이미지 분류에 효과적이다. 따라서 가장 높은 정확도를 보일 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.86      0.90      0.88        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       0.91      0.91      0.91        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.96      0.93      0.95        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.85      0.91      0.88        43\n",
      "           9       0.93      0.88      0.90        32\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.95      0.94      0.94       360\n",
      "weighted avg       0.94      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "sgd_y_pred = sgd_model.predict(X_test)\n",
    "print(classification_report(y_test, sgd_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD model의 정확도는 0.94이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.79      0.96      0.87        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.84      0.88        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.96      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter = 3000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "logistic_y_pred = logistic_model.predict(X_test)\n",
    "print(classification_report(y_test, logistic_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic model의 정확도는 0.96이다. 다섯 개의 모델 중 두 번째로 높은 정확도를 보인다. 로지스틱 회귀는 회귀를 사용하여 데이터가 어떤 클래스에 속할 것인지 확률을 예측하여 그 확률에 따라 데이터를 분류한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.8594940147964341\n",
      "Random Forest: 0.9657883986928104\n",
      "SVM: 0.9895117845117846\n",
      "SGD: 0.9431162266790287\n",
      "Logistic Regression: 0.9552935739864943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print('Decision Tree: {}'.format(precision_score(y_test, decision_tree_y_pred, average='weighted')))\n",
    "print('Random Forest: {}'.format(precision_score(y_test, random_forest_y_pred, average='weighted')))\n",
    "print('SVM: {}'.format(precision_score(y_test, svm_y_pred, average='weighted')))\n",
    "print('SGD: {}'.format(precision_score(y_test, sgd_y_pred, average='weighted')))\n",
    "print('Logistic Regression: {}'.format(precision_score(y_test, logistic_y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손글씨 이미지를 분류하는 작업을 하였다. 손글씨 문제는 각 클래스에 해당하는 숫자를 정확하게 분류하였는지가 중요하기 때문에 Precision 값을 확인하였는데, SVM model이 0.99라는 가장 높은 값을 나타냈다. 이유는 이미지는 2차원 배열을 나타내는데 SVM을 통해서 차원을 높이고 클래스를 분류하였기 때문에 예측 성능이 높았을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 총평"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn을 통하여 내장된 다양한 분류 모델을 사용하여 데이터를 분류하였다. 모델의 성능을 평가할때 accuracy만 확인하고 성능을 확인하였었는데, Recall과 Precision을 알게 되어 목적에 따라 성능지표로 모델을 평가할 수 있음을 배웠다. 손글씨 이미지는 정확하게 분류하는 것이 중요하기 때문에 Recall 값보다 Precision 값이 중요하여 이를 보고 성능을 판단하면 될 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
