{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-7. 프로젝트: 가위바위보 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가위바위보 분류기를 만드는 프로젝트를 진행하였다. 가위바위보 이미지 데이터를 카메라를 통해 직접 사진을 찍어 만들었다. 준비된 이미지 데이터를 분류 모델에 학습시키고 가위, 바위, 보 이미지를 분류하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노트북 전면 카메라를 활용하여 가위, 바위, 보 이미지 각 100장씩 만들었다. 이미지를 한 장씩 찍는 것은 어려움이 있으므로 구글의 teachable machine 사이트를 이용하여 각 이미지를 캡쳐하였다. Image Project를 선택하여 Webcam을 구동하고 이미지 데이터를 직접 촬영할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디렉토리 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 저장하기 위한 디렉토리를 만들었다. rock_scissor_paper 및 하위 디렉토리를 만들었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mkdir -p ~/aiffel/rock_scissor_paper/scissor\n",
    "\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/rock\n",
    "\n",
    "mkdir -p ~/aiffel/rock_scissor_paper/paper\n",
    "\n",
    "ls -l ~/aiffel/rock_scissor_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 및 Resize 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 처리할 수 있는 라이브러인 pillow를 설치하였다. \n",
    "또한, 환경 변수의 os 자원을 제어하고, 폴더 안의 특정 리스트를 가져오기 위해 os와 glob 모듈을 불러왔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in ./anaconda3/envs/aiffel/lib/python3.7/site-packages (8.0.1)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가위 이미지 데이터의 크기가 224*224 이므로 28*28 로 변경하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바위 이미지와 보 이미지도 마찬가지로 이미지 크기를 28*28로 조정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 라벨링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가위, 바위, 보 데이터를 읽을 수 있는 load_data() 함수를 만들었다. load_data() 함수의 입력은 이미지가 있는 폴더 위치를 받는다. 여기서 rock_scissor_paper 폴더 위치로 정하였다. 숫자 손글씨 인식기는 0~9까지의 10개의 클래스였지만, 가위바위보 분류기는 가위, 바위, 보의 3개의 클래스로 나눠진다. 가위: 0, 바위: 1, 보: 2 로 라벨링이 될 것이다. 처음 모델에서는 number_of_data에 300을 대입하였고, 이후에 정확도 향상을 위해 9000을 대입하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 9000 입니다.\n",
      "x_train shape: (9000, 28, 28, 3)\n",
      "y_train shape: (9000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=9000   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째의 이미지를 부르면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가위바위보 데이터셋은 MNIST와 다르게 RGB의 이미지 데이터 셋으로 들어가고, 3개의 클래스로 분류된다. 따라서 input_shape=(28,28,1)를 input_shape=(28,28,3)으로 변경하고, 최종 분류기의 클래스 수를 10에서 3으로 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                51264     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 56,547\n",
      "Trainable params: 56,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설계된 딥러닝 네트워크로 300개의 가위바위보 이미지를 epoch 10번으로 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 [==============================] - 4s 16ms/step - loss: 1.9128 - accuracy: 0.5130\n",
      "Epoch 2/10\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.7411\n",
      "Epoch 3/10\n",
      "282/282 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8523\n",
      "Epoch 4/10\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.2286 - accuracy: 0.9163\n",
      "Epoch 5/10\n",
      "282/282 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9476\n",
      "Epoch 6/10\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9662\n",
      "Epoch 7/10\n",
      "282/282 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9634\n",
      "Epoch 8/10\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 0.1116 - accuracy: 0.9632\n",
      "Epoch 9/10\n",
      "282/282 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9852\n",
      "Epoch 10/10\n",
      "282/282 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f41700c6c90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터가 300일 때는, accuracy가 1.00의 값을 가진다. 학습 데이터의 갯수가 9000일 때는, accuracy가 0.99이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터를 만드는 방법은 학습 데이터를 만드는 방법과 유사하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시험용 데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "\n",
    "def load_test_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"시험용 데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "  \n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시험용 데이터를 학습된 모델에 사용하여 test_accuracy를 측정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 2s - loss: 0.1733 - accuracy: 0.9233\n",
      "test_loss: 0.17331424355506897 \n",
      "test_accuracy: 0.9233333468437195\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test ,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측을 해보니 학습 데이터의 갯수가 300일 때는 0.33의 정확도를 구하였다. 학습 데이터로 모델에서 학습시키면 모델에서의 정확도가 1.00의 값이였는데, 시험용 데이터로 test_accuracy를 구하면 0.33로 상대적으로 낮은 값을 나타낸다. 결과를 통해 학습 모델이 과적합되었다는 것으로 추측할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도 향상을 위한 데이터 augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 이미지당 100개의 적은 수의 이미지로 모델을 학습하였기에 더 많은 이미지를 가져온다면 accuracy가 향상될 수 있다. 총 30명의 이미지 데이터를 불러와 9000장으로 다시 학습시켰다. 가위, 바위, 보의 학습 데이터를 읽을 수 있는 load_data() 함수에서 number_of_data 값을 300에서 9000으로 바꾸어 학습을 진행하였더니 결과는 다음과 같다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10/10 - 2s - loss: 0.1733 - accuracy: 0.9233\n",
    "\n",
    "test_loss: 0.17331424355506897 \n",
    "\n",
    "test_accuracy: 0.9233333468437195"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 통해 정확도가 0.33에서 0.92으로 증가한 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 총평"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 모델에서 정확도가 높다고 적합한 모델이 아닌 것을 알게 되었다. 학습 모델의 정확도가 1에 가깝다면 학습 데이터에 과적합되는 것으로 추측할 수 있다. 이에 따라 테스트 정확도는 좋지 못한 성능의 결과를 가져온다. 이를 해결하기 위해서 데이터를 더 많이 가져온다면 정확도의 향상을 만들어낼 수 있다. 여기서는 정확도 향상을 위한 방법 중 데이터를 증가시키는 방법만을 사용하였는데, 또 다른 방법으로 학습 모델에서 하이퍼파라미터를 변경해보면 더 좋은 성능을 나타내는 모델을 만들 수 있을 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
